# Model configurations for evaluation
# Add models you want to test on Firmus AI Cloud H200 infrastructure
# CUTTING-EDGE MODELS ONLY - December 2024

models:
  # Meta Llama 3.3 (December 2024 - Latest)
  llama3_3_70b:
    name: "Llama-3.3-70B-Instruct"
    model_path: "meta-llama/Llama-3.3-70B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 140
      recommended_vram_gb: 160
    test_parameters:
      batch_sizes: [1, 2, 4, 8]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # Qwen 2.5 Series (November 2024 - Latest from Alibaba)
  qwen2_5_7b:
    name: "Qwen2.5-7B-Instruct"
    model_path: "Qwen/Qwen2.5-7B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 14
      recommended_vram_gb: 20
    test_parameters:
      batch_sizes: [1, 4, 8, 16, 32]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

  qwen2_5_14b:
    name: "Qwen2.5-14B-Instruct"
    model_path: "Qwen/Qwen2.5-14B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 28
      recommended_vram_gb: 36
    test_parameters:
      batch_sizes: [1, 4, 8, 16]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

  qwen2_5_72b:
    name: "Qwen2.5-72B-Instruct"
    model_path: "Qwen/Qwen2.5-72B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 144
      recommended_vram_gb: 160
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

  # DeepSeek V3 (December 2024 - Cutting Edge MoE)
  deepseek_v3:
    name: "DeepSeek-V3"
    model_path: "deepseek-ai/DeepSeek-V3"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 160
      recommended_vram_gb: 200
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # Mistral Large 2 (July 2024 - Latest Mistral)
  mistral_large_2:
    name: "Mistral-Large-Instruct-2407"
    model_path: "mistralai/Mistral-Large-Instruct-2407"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 140
      recommended_vram_gb: 160
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

# Evaluation datasets
datasets:
  quality:
    - name: "MMLU"
      path: "cais/mmlu"
      metrics: ["accuracy"]
    - name: "GSM8K"
      path: "gsm8k"
      metrics: ["accuracy"]
    - name: "HumanEval"
      path: "openai_humaneval"
      metrics: ["pass@1", "pass@10"]

  performance:
    - name: "Custom Benchmark"
      description: "Token generation speed tests"
      metrics: ["tokens_per_second", "latency_ms"]
