# Model configurations for evaluation
# Add models you want to test on Firmus H200 infrastructure
# CUTTING-EDGE MODELS ONLY - 2025 Releases

models:
  # OpenAI GPT-OSS-120B (August 2025 - First OpenAI Open Source Model)
  gpt_oss_120b:
    name: "GPT-OSS-120B"
    model_path: "openai/gpt-oss-120b"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 80
      recommended_vram_gb: 80
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # OpenAI GPT-OSS-20B (August 2025 - Efficient Edge Model)
  gpt_oss_20b:
    name: "GPT-OSS-20B"
    model_path: "openai/gpt-oss-20b"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 16
      recommended_vram_gb: 20
    test_parameters:
      batch_sizes: [1, 2, 4, 8]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # Meta Llama 4 Scout (April 2025 - 10M Context Length)
  llama4_scout:
    name: "Llama-4-Scout-17B-16E"
    model_path: "meta-llama/Llama-4-Scout-17B-16E"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 40
      recommended_vram_gb: 80
    test_parameters:
      batch_sizes: [1, 2, 4, 8]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

  # Meta Llama 4 Maverick (April 2025 - Multimodal MoE)
  llama4_maverick:
    name: "Llama-4-Maverick-17B-128E-Instruct"
    model_path: "meta-llama/Llama-4-Maverick-17B-128E-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 80
      recommended_vram_gb: 160
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # DeepSeek R1 (January 2025 - Reasoning Model)
  deepseek_r1:
    name: "DeepSeek-R1"
    model_path: "deepseek-ai/DeepSeek-R1"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 320
      recommended_vram_gb: 400
    test_parameters:
      batch_sizes: [1, 2]
      sequence_lengths: [512, 1024, 2048, 4096, 8192]

  # DeepSeek R1 Distill Qwen 32B (January 2025 - Distilled Reasoning)
  deepseek_r1_distill_32b:
    name: "DeepSeek-R1-Distill-Qwen-32B"
    model_path: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 64
      recommended_vram_gb: 80
    test_parameters:
      batch_sizes: [1, 2, 4, 8]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

  # Qwen3 235B MoE (April 2025 - Alibaba Flagship)
  qwen3_235b:
    name: "Qwen3-235B-A22B-Instruct"
    model_path: "Qwen/Qwen3-235B-A22B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 120
      recommended_vram_gb: 160
    test_parameters:
      batch_sizes: [1, 2, 4]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384, 32768]

  # Qwen3 32B (April 2025 - Dense Model)
  qwen3_32b:
    name: "Qwen3-32B-Instruct"
    model_path: "Qwen/Qwen3-32B-Instruct"
    type: "causal_lm"
    hardware_requirements:
      min_vram_gb: 64
      recommended_vram_gb: 80
    test_parameters:
      batch_sizes: [1, 2, 4, 8, 16]
      sequence_lengths: [512, 1024, 2048, 4096, 8192, 16384]

# Evaluation datasets
datasets:
  quality:
    - name: "MMLU"
      path: "cais/mmlu"
      metrics: ["accuracy"]
        - name: "GSM8K"
      path: "gsm8k"
      metrics: ["accuracy"]
        - name: "ARC"
      path: "arc"
      metrics: ["accuracy"]
        - name: "WinoGrande"
      path: "winogrande"
      metrics: ["accuracy"]
        - name: "HellaSwag"
      path: "Rowan/hellaswag"
      metrics: ["pass@1", "pass@10"]

performance:
  - name: "Custom Benchmark"
    description: "Token generation speed tests"
    metrics: ["tokens_per_second", "latency_ms"]
