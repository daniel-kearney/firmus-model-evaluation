"""\nEnergy Monitoring Module for Firmus AI Cloud H200 Infrastructure\n\nProvides comprehensive energy tracking for LLM inference with:\n- Joules per token (J/token) - Industry standard metric\n- Wh per 1000 queries - Scalability metric\n- Phase-aware energy attribution (prefill vs decode)\n- Thermal and power throttling detection\n\nOptimized for NVIDIA H200 with 700W TDP and 25ms power sampling.\n"""\n\nimport pynvml\nimport time\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Dict, Optional\nimport json\n\n\n@dataclass\nclass EnergyMetrics:\n    """Comprehensive energy metrics for model inference"""\n    total_energy_joules: float\n    tokens_generated: int\n    joules_per_token: float\n    tokens_per_joule: float  # Efficiency metric\n    avg_power_watts: float\n    peak_power_watts: float\n    duration_seconds: float\n    prefill_energy_joules: float\n    decode_energy_joules: float\n    wh_per_1k_queries: float  # Scalability metric\n    gpu_temp_celsius: Optional[float] = None\n    thermal_throttled: bool = False\n    power_throttled: bool = False\n    \n    def to_dict(self) -> Dict:\n        return asdict(self)\n    \n    def to_json(self) -> str:\n        return json.dumps(self.to_dict(), indent=2)\n\n\nclass H200EnergyMonitor:\n    """\n    NVIDIA H200 Energy Monitor with 25ms power sampling resolution.\n    \n    Tracks GPU power consumption during model inference and calculates\n    normalized energy efficiency metrics suitable for apples-to-apples\n    comparison across different models.\n    """\n    \n    def __init__(self, gpu_index: int = 0, sampling_interval: float = 0.025):\n        """\n        Initialize energy monitor for specified GPU.\n        \n        Args:\n            gpu_index: GPU device index (default: 0)\n            sampling_interval: Power sampling interval in seconds (default: 25ms for H200)\n        """\n        try:\n            pynvml.nvmlInit()\n            self.handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_index)\n            self.gpu_index = gpu_index\n            self.sampling_interval = sampling_interval\n            \n            # Verify H200 capabilities\n            gpu_name = pynvml.nvmlDeviceGetName(self.handle)\n            print(f"Initialized energy monitoring for: {gpu_name}")\n            \n        except pynvml.NVMLError as e:\n            raise RuntimeError(f"Failed to initialize NVML: {e}")\n        \n        self.power_samples = []\n        self.timestamps = []\n        self.start_time = None\n        \n    def start_monitoring(self):\n        """Begin continuous power sampling session"""\n        self.power_samples = []\n        self.timestamps = []\n        self.start_time = time.time()\n        \n    def sample_power(self) -> float:\n        """\n        Sample instantaneous GPU power draw.\n        \n        H200 supports power.draw.instant with ~25ms resolution.\n        \n        Returns:\n            Power draw in watts\n        """\n        try:\n            # Power in milliwatts\n            power_mw = pynvml.nvmlDeviceGetPowerUsage(self.handle)\n            power_watts = power_mw / 1000.0\n            \n            self.power_samples.append(power_watts)\n            self.timestamps.append(time.time())\n            \n            return power_watts\n            \n        except pynvml.NVMLError as e:\n            print(f"Warning: Power sampling error: {e}")\n            return 0\n    \n    def get_thermal_state(self) -> Dict:\n        """\n        Get current thermal and throttling state.\n        \n        Critical for Firmus thermal management optimization.\n        """\n        try:\n            temp = pynvml.nvmlDeviceGetTemperature(\n                self.handle, \n                pynvml.NVML_TEMPERATURE_GPU\n            )\n            \n            throttle_reasons = pynvml.nvmlDeviceGetCurrentClocksThrottleReasons(\n                self.handle\n            )\n            \n            return {\n                'gpu_temp_celsius': temp,\n                'thermal_throttled': bool(\n                    throttle_reasons & pynvml.nvmlClocksThrottleReasonThermalSlowdown\n                ),\n                'power_throttled': bool(\n                    throttle_reasons & pynvml.nvmlClocksThrottleReasonPowerBrake\n                ),\n                'hw_slowdown': bool(\n                    throttle_reasons & pynvml.nvmlClocksThrottleReasonHwSlowdown\n                )\n            }\n        except pynvml.NVMLError:\n            return {\n                'gpu_temp_celsius': None,\n                'thermal_throttled': False,\n                'power_throttled': False,\n                'hw_slowdown': False\n            }\n    \n    def calculate_energy(self, \n                        tokens_generated: int,\n                        prefill_duration: Optional[float] = None) -> EnergyMetrics:\n        """\n        Calculate comprehensive energy metrics from power samples.\n        \n        Uses trapezoidal integration for accurate energy calculation.\n        \n        Args:\n            tokens_generated: Number of output tokens generated\n            prefill_duration: Duration of prefill phase in seconds (optional)\n        \n        Returns:\n            EnergyMetrics object with all efficiency metrics\n        """\n        if len(self.power_samples) < 2:\n            raise ValueError("Insufficient power samples for energy calculation")\n        \n        # Trapezoidal integration of power over time\n        total_energy_joules = 0\n        for i in range(1, len(self.power_samples)):\n            dt = self.timestamps[i] - self.timestamps[i-1]\n            avg_power = (self.power_samples[i] + self.power_samples[i-1]) / 2\n            total_energy_joules += avg_power * dt\n        \n        duration = self.timestamps[-1] - self.timestamps[0]\n        avg_power = sum(self.power_samples) / len(self.power_samples)\n        peak_power = max(self.power_samples)\n        \n        # Phase-aware energy attribution\n        prefill_energy = 0\n        decode_energy = total_energy_joules\n        \n        if prefill_duration and prefill_duration > 0:\n            # Estimate prefill energy assuming similar power draw\n            prefill_energy = avg_power * prefill_duration\n            decode_energy = total_energy_joules - prefill_energy\n        \n        # Calculate normalized metrics\n        joules_per_token = (\n            total_energy_joules / tokens_generated \n            if tokens_generated > 0 else 0\n        )\n        \n        tokens_per_joule = (\n            tokens_generated / total_energy_joules\n            if total_energy_joules > 0 else 0\n        )\n        \n        # Wh per 1000 queries (assuming 1 query = 1 generation)\n        wh_per_1k_queries = (total_energy_joules / 3600) * 1000\n        \n        # Get thermal state\n        thermal_state = self.get_thermal_state()\n        \n        return EnergyMetrics(\n            total_energy_joules=total_energy_joules,\n            tokens_generated=tokens_generated,\n            joules_per_token=joules_per_token,\n            tokens_per_joule=tokens_per_joule,\n            avg_power_watts=avg_power,\n            peak_power_watts=peak_power,\n            duration_seconds=duration,\n            prefill_energy_joules=prefill_energy,\n            decode_energy_joules=decode_energy,\n            wh_per_1k_queries=wh_per_1k_queries,\n            gpu_temp_celsius=thermal_state['gpu_temp_celsius'],\n            thermal_throttled=thermal_state['thermal_throttled'],\n            power_throttled=thermal_state['power_throttled']\n        )\n    \n    def get_gpu_info(self) -> Dict:\n        """Get GPU hardware information"""\n        try:\n            return {\n                'name': pynvml.nvmlDeviceGetName(self.handle),\n                'memory_total_gb': pynvml.nvmlDeviceGetMemoryInfo(self.handle).total / 1e9,\n                'power_limit_watts': pynvml.nvmlDeviceGetPowerManagementLimit(self.handle) / 1000,\n                'driver_version': pynvml.nvmlSystemGetDriverVersion()\n            }\n        except pynvml.NVMLError:\n            return {}\n    \n    def cleanup(self):\n        """Shutdown NVML and release resources"""\n        try:\n            pynvml.nvmlShutdown()\n        except pynvml.NVMLError:\n            pass\n\n\nif __name__ == "__main__":\n    # Example usage\n    monitor = H200EnergyMonitor(gpu_index=0)\n    print("\nGPU Info:")\n    print(json.dumps(monitor.get_gpu_info(), indent=2))\n    \n    print("\nThermal State:")\n    print(json.dumps(monitor.get_thermal_state(), indent=2))\n    \n    monitor.cleanup()\n
